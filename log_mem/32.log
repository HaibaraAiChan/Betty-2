main start at this time 1671831740.0587614
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 1.34375 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 1.6796875 GB
    Memory Allocated: 0.3182086944580078  GigaBytes
Max Memory Allocated: 0.3182086944580078  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 1.6796875 GB
    Memory Allocated: 0.3182086944580078  GigaBytes
Max Memory Allocated: 0.3182086944580078  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 1.787109375 GB
    Memory Allocated: 0.34798431396484375  GigaBytes
Max Memory Allocated: 0.34798431396484375  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 1.787109375 GB
    Memory Allocated: 0.34798431396484375  GigaBytes
Max Memory Allocated: 0.34798431396484375  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.787109375 GB
    Memory Allocated: 0.34946632385253906  GigaBytes
Max Memory Allocated: 0.34947919845581055  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.08374595642089844

bucketing time:  0.002214670181274414
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 2.904296875 GB
    Memory Allocated: 0.6248698234558105  GigaBytes
Max Memory Allocated: 1.3623805046081543  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0948)
------------------------------------- after loss backward 
 Nvidia-smi: 2.9140625 GB
    Memory Allocated: 0.3849453926086426  GigaBytes
Max Memory Allocated: 1.3623805046081543  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 2.9140625 GB
    Memory Allocated: 0.34978675842285156  GigaBytes
Max Memory Allocated: 1.3623805046081543  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 2.9140625 GB
    Memory Allocated: 0.350527286529541  GigaBytes
Max Memory Allocated: 1.3623805046081543  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09493136405944824

core.py bucket local nid tensor([   0,    1,    2,  ..., 6129, 6130, 6131], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0010116100311279297
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.28125 GB
    Memory Allocated: 0.8361930847167969  GigaBytes
Max Memory Allocated: 1.5766024589538574  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1461)
------------------------------------ after loss backward 
 Nvidia-smi: 3.28125 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.5766024589538574  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.28125 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.5766024589538574  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08308720588684082

core.py bucket local nid tensor([ 6132,  6133,  6134,  ..., 12274, 12275, 12276], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009663105010986328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1452)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08856916427612305

core.py bucket local nid tensor([12277, 12278, 12279,  ..., 18448, 18449, 18450], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009963512420654297
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1463)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08980965614318848

core.py bucket local nid tensor([18451, 18452, 18453,  ..., 24595, 24596, 24597], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009634494781494141
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1486)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08230113983154297

core.py bucket local nid tensor([24598, 24599, 24600,  ..., 30745, 30746, 30747], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009598731994628906
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1463)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08508968353271484

core.py bucket local nid tensor([30748, 30749, 30750,  ..., 36883, 36884, 36885], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009615421295166016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1466)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08293342590332031

core.py bucket local nid tensor([36886, 36887, 36888,  ..., 43033, 43034, 43035], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009515285491943359
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1492)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08317995071411133

core.py bucket local nid tensor([43036, 43037, 43038,  ..., 49181, 49182, 49183], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009584426879882812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1468)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08356499671936035

core.py bucket local nid tensor([49184, 49185, 49186,  ..., 55315, 55316, 55317], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009624958038330078
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1524)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08599162101745605

core.py bucket local nid tensor([55318, 55319, 55320,  ..., 61459, 61460, 61461], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009596347808837891
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1445)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08380317687988281

core.py bucket local nid tensor([61462, 61463, 61464,  ..., 67595, 67596, 67597], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0009648799896240234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1483)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0834665298461914

core.py bucket local nid tensor([67598, 67599, 67600,  ..., 73741, 73742, 73743], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009758472442626953
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1448)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08361411094665527

core.py bucket local nid tensor([73744, 73745, 73746,  ..., 79904, 79905, 79906], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009467601776123047
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1470)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0839228630065918

core.py bucket local nid tensor([79907, 79908, 79909,  ..., 86045, 86046, 86047], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009708404541015625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1446)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08406639099121094

core.py bucket local nid tensor([86048, 86050, 86051,  ..., 92187, 92188, 92189], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009524822235107422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1475)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08538365364074707

core.py bucket local nid tensor([92190, 92191, 92192,  ..., 98331, 98332, 98333], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009844303131103516
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1473)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08378720283508301

core.py bucket local nid tensor([ 98334,  98335,  98336,  ..., 104466, 104467, 104468], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009491443634033203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1480)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08539414405822754

core.py bucket local nid tensor([104469, 104470, 104471,  ..., 110595, 110596, 110597], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.00096893310546875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1479)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08386969566345215

core.py bucket local nid tensor([110598, 110599, 110600,  ..., 116737, 116738, 116739], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009555816650390625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1457)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08538532257080078

core.py bucket local nid tensor([116740, 116741, 116742,  ..., 122870, 122871, 122872], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009677410125732422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1459)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08315014839172363

core.py bucket local nid tensor([122873, 122874, 122875,  ..., 128991, 128992, 128993], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0009515285491943359
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1457)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09646105766296387

core.py bucket local nid tensor([128994, 128995, 128996,  ..., 135126, 135127, 135128], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0010039806365966797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1452)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09049201011657715

core.py bucket local nid tensor([135129, 135130, 135131,  ..., 141251, 141252, 141253], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009884834289550781
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1466)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09298253059387207

core.py bucket local nid tensor([141254, 141255, 141256,  ..., 147394, 147395, 147396], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009710788726806641
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1460)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09065485000610352

core.py bucket local nid tensor([147397, 147398, 147399,  ..., 153540, 153541, 153542], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0009555816650390625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1451)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09067440032958984

core.py bucket local nid tensor([153544, 153545, 153546,  ..., 159679, 159680, 159681], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009615421295166016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1471)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08520174026489258

core.py bucket local nid tensor([159682, 159683, 159684,  ..., 165831, 165832, 165833], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009608268737792969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1476)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08889603614807129

core.py bucket local nid tensor([165834, 165835, 165836,  ..., 171991, 171992, 171993], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009636878967285156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1475)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08181428909301758

core.py bucket local nid tensor([171994, 171995, 171996,  ..., 178151, 178153, 178154], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009715557098388672
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1477)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08231854438781738

core.py bucket local nid tensor([178155, 178156, 178157,  ..., 184301, 184302, 184303], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009582042694091797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1465)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08919787406921387

core.py bucket local nid tensor([184304, 184305, 184306,  ..., 190449, 190450, 190451], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009622573852539062
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8376178741455078  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1475)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865790367126465  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3865785598754883  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08146333694458008

core.py bucket local nid tensor([190452, 190453, 190454,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009548664093017578
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.8363170623779297  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1455)
------------------------------------ after loss backward 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.38611602783203125  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.34978675842285156  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.7918)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3504619598388672  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3504619598388672  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.66845703125  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.66845703125  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.6982326507568359  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.34912109375  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.35546875 GB
    Memory Allocated: 0.3506031036376953  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.08043456077575684

bucketing time:  0.0011942386627197266
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6259455680847168  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0937)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.385744571685791  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3505859375  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35132646560668945  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09272170066833496

core.py bucket local nid tensor([   0,    1,    2,  ..., 6142, 6143, 6144], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009541511535644531
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8367829322814941  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1479)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6124448776245117  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08850312232971191

core.py bucket local nid tensor([ 6145,  6146,  6147,  ..., 12288, 12289, 12290], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009572505950927734
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8400936126708984  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1440)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08181238174438477

core.py bucket local nid tensor([12291, 12292, 12293,  ..., 18418, 18419, 18420], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.000965118408203125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1431)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08202576637268066

core.py bucket local nid tensor([18421, 18422, 18423,  ..., 24548, 24549, 24550], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009551048278808594
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1454)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08764910697937012

core.py bucket local nid tensor([24551, 24552, 24553,  ..., 30692, 30693, 30694], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009655952453613281
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1450)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08208656311035156

core.py bucket local nid tensor([30695, 30697, 30698,  ..., 36851, 36852, 36853], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009584426879882812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1449)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08458733558654785

core.py bucket local nid tensor([36854, 36855, 36856,  ..., 43000, 43001, 43002], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009791851043701172
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1461)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08257555961608887

core.py bucket local nid tensor([43003, 43004, 43005,  ..., 49136, 49137, 49138], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009615421295166016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1448)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09589076042175293

core.py bucket local nid tensor([49140, 49141, 49142,  ..., 55295, 55296, 55297], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009658336639404297
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1446)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08274483680725098

core.py bucket local nid tensor([55298, 55299, 55300,  ..., 61438, 61439, 61440], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009658336639404297
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1435)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09017634391784668

core.py bucket local nid tensor([61441, 61442, 61443,  ..., 67586, 67587, 67588], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0009703636169433594
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1451)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08823633193969727

core.py bucket local nid tensor([67589, 67590, 67591,  ..., 73734, 73735, 73736], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009629726409912109
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1453)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08532094955444336

core.py bucket local nid tensor([73737, 73738, 73739,  ..., 79873, 79874, 79875], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009756088256835938
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1439)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08267879486083984

core.py bucket local nid tensor([79876, 79877, 79878,  ..., 86012, 86013, 86014], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009632110595703125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1441)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0831754207611084

core.py bucket local nid tensor([86015, 86016, 86017,  ..., 92158, 92159, 92160], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009663105010986328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1473)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08620166778564453

core.py bucket local nid tensor([92161, 92162, 92163,  ..., 98307, 98308, 98309], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009613037109375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1431)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08289098739624023

core.py bucket local nid tensor([ 98310,  98311,  98312,  ..., 104463, 104464, 104465], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009770393371582031
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1450)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08199858665466309

core.py bucket local nid tensor([104466, 104467, 104468,  ..., 110591, 110592, 110593], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0009529590606689453
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1462)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08234882354736328

core.py bucket local nid tensor([110594, 110595, 110596,  ..., 116721, 116722, 116723], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.000988006591796875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1443)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0818183422088623

core.py bucket local nid tensor([116724, 116725, 116726,  ..., 122857, 122858, 122859], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009570121765136719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1468)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08401966094970703

core.py bucket local nid tensor([122860, 122861, 122862,  ..., 129008, 129009, 129010], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0013251304626464844
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1461)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08233761787414551

core.py bucket local nid tensor([129011, 129012, 129013,  ..., 135143, 135144, 135145], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0009527206420898438
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1433)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08935070037841797

core.py bucket local nid tensor([135146, 135147, 135148,  ..., 141294, 141295, 141296], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0010867118835449219
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1435)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0816338062286377

core.py bucket local nid tensor([141297, 141298, 141299,  ..., 147445, 147446, 147447], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009655952453613281
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1437)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08237481117248535

core.py bucket local nid tensor([147448, 147449, 147450,  ..., 153585, 153586, 153587], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0009446144104003906
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1450)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0826575756072998

core.py bucket local nid tensor([153588, 153589, 153590,  ..., 159741, 159742, 159743], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009417533874511719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1446)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08331704139709473

core.py bucket local nid tensor([159744, 159745, 159746,  ..., 165882, 165883, 165884], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009539127349853516
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1446)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08210515975952148

core.py bucket local nid tensor([165885, 165886, 165887,  ..., 172009, 172010, 172011], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009520053863525391
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1456)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08193135261535645

core.py bucket local nid tensor([172012, 172013, 172014,  ..., 178166, 178167, 178168], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009570121765136719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1459)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08197426795959473

core.py bucket local nid tensor([178169, 178170, 178171,  ..., 184329, 184330, 184331], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009639263153076172
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1418)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08264899253845215

core.py bucket local nid tensor([184332, 184333, 184334,  ..., 190467, 190468, 190469], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009484291076660156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384184837341309  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1447)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873782157897949  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3873777389526367  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08198761940002441

core.py bucket local nid tensor([190470, 190471, 190472,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009622573852539062
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8371162414550781  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1445)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3869152069091797  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3505859375  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.7273)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3505859375  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3505859375  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.66845703125  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.66845703125  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6982326507568359  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3489971160888672  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35109424591064453  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.07803201675415039

bucketing time:  0.0011758804321289062
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6270403861999512  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0926)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38623571395874023  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35181760787963867  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08400464057922363

core.py bucket local nid tensor([   0,    1,    2,  ..., 6137, 6138, 6139], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009963512420654297
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8375606536865234  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1416)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6142463684082031  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0833592414855957

core.py bucket local nid tensor([ 6140,  6141,  6142,  ..., 12300, 12301, 12302], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009889602661132812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8406128883361816  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1444)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.082855224609375

core.py bucket local nid tensor([12303, 12304, 12305,  ..., 18432, 18433, 18434], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0010590553283691406
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1427)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08339905738830566

core.py bucket local nid tensor([18435, 18436, 18437,  ..., 24573, 24574, 24575], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009813308715820312
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1432)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08319926261901855

core.py bucket local nid tensor([24577, 24578, 24579,  ..., 30721, 30722, 30723], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009818077087402344
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1436)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08321356773376465

core.py bucket local nid tensor([30724, 30725, 30726,  ..., 36873, 36874, 36875], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009930133819580078
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1424)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08342218399047852

core.py bucket local nid tensor([36876, 36877, 36878,  ..., 43019, 43020, 43021], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.000997304916381836
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1418)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08411717414855957

core.py bucket local nid tensor([43022, 43023, 43024,  ..., 49157, 49158, 49159], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0010292530059814453
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1429)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08519625663757324

core.py bucket local nid tensor([49160, 49161, 49162,  ..., 55284, 55285, 55286], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0010020732879638672
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1420)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08372259140014648

core.py bucket local nid tensor([55287, 55288, 55289,  ..., 61421, 61422, 61423], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.000978708267211914
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1415)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0835719108581543

core.py bucket local nid tensor([61424, 61425, 61426,  ..., 67558, 67559, 67560], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.000986337661743164
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1433)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0852811336517334

core.py bucket local nid tensor([67561, 67562, 67563,  ..., 73696, 73697, 73698], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009822845458984375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1422)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08396553993225098

core.py bucket local nid tensor([73699, 73700, 73701,  ..., 79865, 79866, 79867], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009860992431640625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1429)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08394718170166016

core.py bucket local nid tensor([79868, 79869, 79870,  ..., 86009, 86010, 86011], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009839534759521484
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1480)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08405900001525879

core.py bucket local nid tensor([86012, 86013, 86014,  ..., 92149, 92150, 92151], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009753704071044922
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1430)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08689546585083008

core.py bucket local nid tensor([92152, 92153, 92154,  ..., 98321, 98322, 98323], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009891986846923828
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1417)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08434748649597168

core.py bucket local nid tensor([ 98325,  98326,  98327,  ..., 104465, 104466, 104467], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009851455688476562
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1441)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08498406410217285

core.py bucket local nid tensor([104468, 104469, 104471,  ..., 110599, 110600, 110601], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0009772777557373047
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1425)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08426737785339355

core.py bucket local nid tensor([110602, 110603, 110604,  ..., 116761, 116762, 116763], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009818077087402344
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1423)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08419370651245117

core.py bucket local nid tensor([116764, 116765, 116766,  ..., 122917, 122918, 122919], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009789466857910156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1419)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08432221412658691

core.py bucket local nid tensor([122920, 122921, 122922,  ..., 129046, 129047, 129048], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.000988006591796875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1451)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08438563346862793

core.py bucket local nid tensor([129049, 129050, 129051,  ..., 135193, 135194, 135195], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0009922981262207031
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1422)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08417272567749023

core.py bucket local nid tensor([135196, 135197, 135198,  ..., 141327, 141328, 141329], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009777545928955078
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1429)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08461856842041016

core.py bucket local nid tensor([141330, 141331, 141332,  ..., 147470, 147471, 147472], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009698867797851562
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1416)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08411073684692383

core.py bucket local nid tensor([147473, 147474, 147475,  ..., 153611, 153612, 153613], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0010013580322265625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1418)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08404684066772461

core.py bucket local nid tensor([153614, 153615, 153616,  ..., 159739, 159740, 159741], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009999275207519531
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1422)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08393311500549316

core.py bucket local nid tensor([159742, 159743, 159744,  ..., 165887, 165888, 165889], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009875297546386719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1412)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08428740501403809

core.py bucket local nid tensor([165890, 165891, 165892,  ..., 172017, 172018, 172019], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0010104179382324219
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1458)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08487343788146973

core.py bucket local nid tensor([172020, 172021, 172022,  ..., 178169, 178170, 178171], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.001007080078125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1429)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08398032188415527

core.py bucket local nid tensor([178172, 178173, 178174,  ..., 184325, 184326, 184327], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009789466857910156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1442)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08398556709289551

core.py bucket local nid tensor([184328, 184329, 184330,  ..., 190463, 190464, 190465], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009844303131103516
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1424)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761186599731445  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08435845375061035

core.py bucket local nid tensor([190466, 190467, 190468,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009732246398925781
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8376250267028809  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1408)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874063491821289  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.6635)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.668576717376709  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.668576717376709  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6983523368835449  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.34862565994262695  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35010766983032227  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.07942652702331543

bucketing time:  0.0011856555938720703
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6255874633789062  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0915)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38524913787841797  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35009050369262695  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3508310317993164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09477543830871582

core.py bucket local nid tensor([   0,    1,    2,  ..., 6143, 6144, 6145], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.000997781753540039
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8368110656738281  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1408)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08763456344604492

core.py bucket local nid tensor([ 6146,  6147,  6148,  ..., 12288, 12289, 12290], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0010237693786621094
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8395953178405762  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1392)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09466934204101562

core.py bucket local nid tensor([12291, 12292, 12293,  ..., 18434, 18435, 18436], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.001004934310913086
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1399)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08620381355285645

core.py bucket local nid tensor([18437, 18438, 18439,  ..., 24587, 24588, 24589], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.000978231430053711
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1421)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08579039573669434

core.py bucket local nid tensor([24590, 24591, 24592,  ..., 30723, 30724, 30725], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009889602661132812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1399)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08611845970153809

core.py bucket local nid tensor([30726, 30727, 30728,  ..., 36886, 36887, 36888], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.000972747802734375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1414)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0841822624206543

core.py bucket local nid tensor([36889, 36890, 36891,  ..., 43058, 43059, 43060], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009696483612060547
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1412)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08393239974975586

core.py bucket local nid tensor([43061, 43062, 43063,  ..., 49199, 49200, 49201], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009748935699462891
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1392)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09201431274414062

core.py bucket local nid tensor([49202, 49203, 49204,  ..., 55327, 55328, 55329], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009920597076416016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1410)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08554577827453613

core.py bucket local nid tensor([55330, 55331, 55332,  ..., 61468, 61471, 61472], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0010089874267578125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1411)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0844266414642334

core.py bucket local nid tensor([61473, 61474, 61475,  ..., 67622, 67623, 67625], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0010066032409667969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1413)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08428359031677246

core.py bucket local nid tensor([67626, 67628, 67629,  ..., 73773, 73774, 73775], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1404)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08493757247924805

core.py bucket local nid tensor([73776, 73777, 73778,  ..., 79921, 79922, 79923], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0012712478637695312
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1408)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08434391021728516

core.py bucket local nid tensor([79924, 79925, 79926,  ..., 86055, 86056, 86057], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009834766387939453
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1415)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08441805839538574

core.py bucket local nid tensor([86058, 86059, 86060,  ..., 92187, 92188, 92189], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0010991096496582031
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1390)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08422088623046875

core.py bucket local nid tensor([92190, 92191, 92192,  ..., 98318, 98319, 98320], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009837150573730469
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1431)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08449125289916992

core.py bucket local nid tensor([ 98322,  98323,  98324,  ..., 104479, 104480, 104481], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009849071502685547
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1412)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08435988426208496

core.py bucket local nid tensor([104482, 104483, 104484,  ..., 110626, 110627, 110628], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1390)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08430624008178711

core.py bucket local nid tensor([110629, 110630, 110631,  ..., 116772, 116773, 116774], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0010404586791992188
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1401)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08509325981140137

core.py bucket local nid tensor([116775, 116776, 116777,  ..., 122915, 122916, 122917], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009806156158447266
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1394)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08461141586303711

core.py bucket local nid tensor([122918, 122919, 122920,  ..., 129079, 129080, 129081], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0009753704071044922
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1402)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0847327709197998

core.py bucket local nid tensor([129082, 129083, 129084,  ..., 135223, 135224, 135225], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0009756088256835938
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1394)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08460044860839844

core.py bucket local nid tensor([135226, 135227, 135228,  ..., 141346, 141347, 141348], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009770393371582031
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1412)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08466053009033203

core.py bucket local nid tensor([141349, 141350, 141351,  ..., 147461, 147462, 147463], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009801387786865234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1412)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08451676368713379

core.py bucket local nid tensor([147464, 147465, 147467,  ..., 153590, 153591, 153592], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0009932518005371094
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1407)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08440613746643066

core.py bucket local nid tensor([153593, 153594, 153595,  ..., 159741, 159742, 159743], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009822845458984375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1397)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08465194702148438

core.py bucket local nid tensor([159744, 159745, 159747,  ..., 165886, 165887, 165888], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0010166168212890625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1434)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08481168746948242

core.py bucket local nid tensor([165889, 165890, 165891,  ..., 172037, 172038, 172039], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009741783142089844
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1414)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08479666709899902

core.py bucket local nid tensor([172040, 172041, 172042,  ..., 178183, 178184, 178185], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009725093841552734
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1429)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08508563041687012

core.py bucket local nid tensor([178186, 178188, 178189,  ..., 184313, 184314, 184315], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379216194152832  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1441)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3868827819824219  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08446431159973145

core.py bucket local nid tensor([184316, 184317, 184318,  ..., 190478, 190479, 190480], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009756088256835938
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384466171264648  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1417)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635921478271484  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38635873794555664  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08469796180725098

core.py bucket local nid tensor([190481, 190482, 190483,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009827613830566406
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8366208076477051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1397)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38641977310180664  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35009050369262695  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.5988)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35009050369262695  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35009050369262695  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.668576717376709  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.668576717376709  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6983523368835449  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3496122360229492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35109424591064453  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.07960152626037598

bucketing time:  0.0011904239654541016
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.626497745513916  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0904)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38623571395874023  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35181760787963867  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08386015892028809

core.py bucket local nid tensor([   0,    1,    2,  ..., 6129, 6130, 6131], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009958744049072266
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8372740745544434  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1386)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08423256874084473

core.py bucket local nid tensor([ 6132,  6133,  6134,  ..., 12285, 12286, 12287], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009834766387939453
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8395624160766602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1394)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08458209037780762

core.py bucket local nid tensor([12288, 12289, 12290,  ..., 18429, 18430, 18431], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009677410125732422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1377)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08465242385864258

core.py bucket local nid tensor([18432, 18433, 18434,  ..., 24575, 24576, 24577], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009887218475341797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1377)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08431482315063477

core.py bucket local nid tensor([24578, 24579, 24580,  ..., 30718, 30719, 30720], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009801387786865234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1387)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08431077003479004

core.py bucket local nid tensor([30721, 30722, 30724,  ..., 36855, 36856, 36857], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009949207305908203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1401)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08462381362915039

core.py bucket local nid tensor([36858, 36859, 36860,  ..., 42993, 42994, 42995], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009710788726806641
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1376)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08591318130493164

core.py bucket local nid tensor([42996, 42997, 42998,  ..., 49126, 49127, 49128], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0010013580322265625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1397)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0865488052368164

core.py bucket local nid tensor([49129, 49130, 49131,  ..., 55262, 55263, 55264], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009846687316894531
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1376)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08513259887695312

core.py bucket local nid tensor([55265, 55266, 55267,  ..., 61398, 61399, 61400], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009801387786865234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1384)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0850210189819336

core.py bucket local nid tensor([61401, 61402, 61403,  ..., 67546, 67547, 67548], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.001005411148071289
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1398)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08505105972290039

core.py bucket local nid tensor([67549, 67550, 67551,  ..., 73693, 73694, 73695], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1400)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08510446548461914

core.py bucket local nid tensor([73696, 73697, 73698,  ..., 79841, 79842, 79843], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009729862213134766
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1438)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08519220352172852

core.py bucket local nid tensor([79844, 79845, 79846,  ..., 86020, 86021, 86022], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009806156158447266
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1389)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08519959449768066

core.py bucket local nid tensor([86023, 86024, 86025,  ..., 92164, 92165, 92166], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009756088256835938
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1378)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08539128303527832

core.py bucket local nid tensor([92167, 92168, 92169,  ..., 98308, 98309, 98310], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009832382202148438
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1387)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08617544174194336

core.py bucket local nid tensor([ 98311,  98312,  98313,  ..., 104447, 104448, 104449], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.000978231430053711
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1379)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08664727210998535

core.py bucket local nid tensor([104450, 104451, 104452,  ..., 110581, 110582, 110583], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.000995635986328125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1374)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08655285835266113

core.py bucket local nid tensor([110584, 110585, 110586,  ..., 116736, 116737, 116738], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009739398956298828
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1389)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08591938018798828

core.py bucket local nid tensor([116739, 116740, 116741,  ..., 122888, 122889, 122890], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009784698486328125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1385)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08589506149291992

core.py bucket local nid tensor([122891, 122892, 122893,  ..., 129046, 129047, 129048], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0009839534759521484
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1391)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09580349922180176

core.py bucket local nid tensor([129049, 129050, 129051,  ..., 135188, 135189, 135190], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0009839534759521484
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1374)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08467674255371094

core.py bucket local nid tensor([135192, 135193, 135194,  ..., 141330, 141331, 141333], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009760856628417969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1401)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08500075340270996

core.py bucket local nid tensor([141334, 141335, 141336,  ..., 147461, 147462, 147463], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.000986337661743164
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1383)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08581113815307617

core.py bucket local nid tensor([147464, 147465, 147466,  ..., 153590, 153591, 153592], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0009694099426269531
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1395)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08735847473144531

core.py bucket local nid tensor([153593, 153594, 153595,  ..., 159735, 159736, 159737], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0010082721710205078
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1382)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08545136451721191

core.py bucket local nid tensor([159738, 159739, 159740,  ..., 165872, 165873, 165874], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009722709655761719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1432)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08562994003295898

core.py bucket local nid tensor([165875, 165876, 165877,  ..., 172009, 172010, 172011], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009875297546386719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1391)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08506560325622559

core.py bucket local nid tensor([172012, 172013, 172014,  ..., 178157, 178158, 178159], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009737014770507812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1380)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08530902862548828

core.py bucket local nid tensor([178160, 178161, 178162,  ..., 184310, 184311, 184312], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009827613830566406
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1381)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38771629333496094  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0845479965209961

core.py bucket local nid tensor([184313, 184314, 184315,  ..., 190452, 190453, 190454], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009734630584716797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389081954956055  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1381)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774585723876953  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38774538040161133  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08476400375366211

core.py bucket local nid tensor([190455, 190456, 190457,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009758472442626953
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8376369476318359  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1388)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874063491821289  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.5354)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6685676574707031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6685676574707031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6983432769775391  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3486166000366211  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35071372985839844  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.07991433143615723

bucketing time:  0.0011644363403320312
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6266598701477051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0893)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38585519790649414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3506965637207031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3514370918273926  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08425545692443848

core.py bucket local nid tensor([   0,    1,    2,  ..., 6122, 6123, 6124], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009889602661132812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8371801376342773  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1388)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08363580703735352

core.py bucket local nid tensor([ 6125,  6126,  6127,  ..., 12263, 12264, 12265], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009846687316894531
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8402323722839355  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1365)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08397507667541504

core.py bucket local nid tensor([12266, 12267, 12268,  ..., 18402, 18403, 18404], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009739398956298828
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1370)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08503460884094238

core.py bucket local nid tensor([18405, 18406, 18407,  ..., 24531, 24532, 24533], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009748935699462891
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1384)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08433985710144043

core.py bucket local nid tensor([24534, 24535, 24536,  ..., 30678, 30679, 30680], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009915828704833984
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1362)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08444881439208984

core.py bucket local nid tensor([30681, 30682, 30683,  ..., 36855, 36856, 36857], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0010142326354980469
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1367)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08483481407165527

core.py bucket local nid tensor([36858, 36859, 36860,  ..., 43004, 43005, 43006], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.001260519027709961
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1368)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0846860408782959

core.py bucket local nid tensor([43007, 43008, 43009,  ..., 49153, 49154, 49155], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0011060237884521484
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1382)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08449530601501465

core.py bucket local nid tensor([49156, 49157, 49158,  ..., 55301, 55302, 55303], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009872913360595703
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1388)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08458709716796875

core.py bucket local nid tensor([55304, 55305, 55306,  ..., 61431, 61432, 61433], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009801387786865234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1362)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08480048179626465

core.py bucket local nid tensor([61434, 61435, 61436,  ..., 67583, 67584, 67585], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0009839534759521484
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1352)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08503341674804688

core.py bucket local nid tensor([67586, 67587, 67588,  ..., 73746, 73747, 73748], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0010371208190917969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1359)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08519268035888672

core.py bucket local nid tensor([73749, 73750, 73751,  ..., 79880, 79881, 79882], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009911060333251953
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1387)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08547830581665039

core.py bucket local nid tensor([79883, 79884, 79886,  ..., 86021, 86022, 86024], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0010039806365966797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1367)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08719420433044434

core.py bucket local nid tensor([86025, 86026, 86027,  ..., 92159, 92160, 92161], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.001013040542602539
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1355)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08594846725463867

core.py bucket local nid tensor([92162, 92163, 92164,  ..., 98308, 98309, 98310], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.001001119613647461
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1385)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08541393280029297

core.py bucket local nid tensor([ 98312,  98313,  98315,  ..., 104455, 104456, 104457], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009860992431640625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1354)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08645439147949219

core.py bucket local nid tensor([104458, 104459, 104460,  ..., 110609, 110610, 110611], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.000990152359008789
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1358)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08516335487365723

core.py bucket local nid tensor([110612, 110613, 110614,  ..., 116750, 116751, 116752], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009865760803222656
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1381)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08567047119140625

core.py bucket local nid tensor([116753, 116754, 116755,  ..., 122882, 122883, 122884], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009932518005371094
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1366)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08631753921508789

core.py bucket local nid tensor([122885, 122886, 122887,  ..., 129012, 129013, 129014], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0009877681732177734
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1380)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0862114429473877

core.py bucket local nid tensor([129015, 129016, 129017,  ..., 135156, 135157, 135158], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.000990152359008789
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1367)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08585596084594727

core.py bucket local nid tensor([135159, 135160, 135161,  ..., 141286, 141288, 141289], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0010077953338623047
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1358)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08519124984741211

core.py bucket local nid tensor([141290, 141291, 141292,  ..., 147432, 147433, 147434], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009760856628417969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1371)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08605074882507324

core.py bucket local nid tensor([147435, 147436, 147437,  ..., 153558, 153559, 153560], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0010161399841308594
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1380)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0855565071105957

core.py bucket local nid tensor([153561, 153562, 153563,  ..., 159714, 159715, 159716], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009772777557373047
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1376)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08568525314331055

core.py bucket local nid tensor([159717, 159718, 159719,  ..., 165835, 165837, 165838], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.001013040542602539
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1352)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08682107925415039

core.py bucket local nid tensor([165839, 165840, 165841,  ..., 171976, 171977, 171978], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0010058879852294922
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1370)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08631229400634766

core.py bucket local nid tensor([171979, 171980, 171981,  ..., 178114, 178115, 178116], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.000988006591796875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1378)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09394025802612305

core.py bucket local nid tensor([178117, 178118, 178120,  ..., 184270, 184271, 184272], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.000997781753540039
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838557243347168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1345)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38748884201049805  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08576154708862305

core.py bucket local nid tensor([184273, 184274, 184275,  ..., 190447, 190448, 190449], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388156890869141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1376)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723182678222656  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38723134994506836  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08528375625610352

core.py bucket local nid tensor([190450, 190451, 190452,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8372445106506348  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1358)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3870258331298828  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3506965637207031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.4706)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3506965637207031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3506965637207031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6685676574707031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6685676574707031  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6983432769775391  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3489971160888672  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3504791259765625  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.08279991149902344

bucketing time:  0.0011858940124511719
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6259589195251465  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0882)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3856205940246582  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3504619598388672  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35120248794555664  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0854041576385498

core.py bucket local nid tensor([   0,    1,    2,  ..., 6129, 6130, 6131], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009822845458984375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8371825218200684  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1338)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08515739440917969

core.py bucket local nid tensor([ 6132,  6133,  6134,  ..., 12261, 12262, 12263], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009808540344238281
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8399667739868164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1363)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08715319633483887

core.py bucket local nid tensor([12264, 12265, 12266,  ..., 18402, 18403, 18404], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009815692901611328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1343)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08558154106140137

core.py bucket local nid tensor([18405, 18406, 18407,  ..., 24550, 24551, 24552], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.00101470947265625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1332)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08936333656311035

core.py bucket local nid tensor([24553, 24555, 24556,  ..., 30684, 30685, 30686], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.000978708267211914
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1356)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08613157272338867

core.py bucket local nid tensor([30687, 30688, 30689,  ..., 36828, 36829, 36830], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009722709655761719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1355)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0860757827758789

core.py bucket local nid tensor([36831, 36832, 36833,  ..., 42975, 42976, 42977], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009708404541015625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1345)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0862271785736084

core.py bucket local nid tensor([42978, 42979, 42980,  ..., 49111, 49112, 49113], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009725093841552734
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1351)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08625054359436035

core.py bucket local nid tensor([49114, 49115, 49116,  ..., 55253, 55254, 55255], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009849071502685547
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1351)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0860133171081543

core.py bucket local nid tensor([55256, 55257, 55258,  ..., 61377, 61378, 61379], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009655952453613281
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1345)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08603119850158691

core.py bucket local nid tensor([61380, 61381, 61382,  ..., 67521, 67522, 67523], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0009806156158447266
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1344)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08800768852233887

core.py bucket local nid tensor([67524, 67525, 67526,  ..., 73673, 73674, 73675], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009779930114746094
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1344)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08684945106506348

core.py bucket local nid tensor([73676, 73677, 73678,  ..., 79819, 79820, 79821], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009737014770507812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1335)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08679389953613281

core.py bucket local nid tensor([79822, 79823, 79824,  ..., 85962, 85963, 85964], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009744167327880859
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1351)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08776116371154785

core.py bucket local nid tensor([85965, 85966, 85967,  ..., 92101, 92102, 92103], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009784698486328125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1348)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08716559410095215

core.py bucket local nid tensor([92104, 92105, 92106,  ..., 98248, 98249, 98250], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009799003601074219
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1348)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0867466926574707

core.py bucket local nid tensor([ 98251,  98252,  98253,  ..., 104416, 104417, 104418], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.000993490219116211
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1344)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.09515500068664551

core.py bucket local nid tensor([104419, 104420, 104421,  ..., 110569, 110570, 110571], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0010068416595458984
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1352)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08708834648132324

core.py bucket local nid tensor([110572, 110573, 110574,  ..., 116717, 116718, 116719], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009725093841552734
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1370)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0874032974243164

core.py bucket local nid tensor([116720, 116721, 116722,  ..., 122857, 122858, 122859], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009815692901611328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1356)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08702659606933594

core.py bucket local nid tensor([122860, 122861, 122862,  ..., 129024, 129025, 129026], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0009763240814208984
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1354)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08720588684082031

core.py bucket local nid tensor([129027, 129028, 129029,  ..., 135169, 135170, 135171], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0009794235229492188
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1349)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08694124221801758

core.py bucket local nid tensor([135172, 135173, 135174,  ..., 141319, 141320, 141321], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009944438934326172
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1352)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08756566047668457

core.py bucket local nid tensor([141322, 141323, 141324,  ..., 147477, 147478, 147479], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0012564659118652344
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1338)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08778858184814453

core.py bucket local nid tensor([147480, 147481, 147482,  ..., 153626, 153627, 153628], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0010943412780761719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1369)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08668231964111328

core.py bucket local nid tensor([153629, 153630, 153631,  ..., 159762, 159763, 159764], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009813308715820312
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1362)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08675861358642578

core.py bucket local nid tensor([159765, 159766, 159767,  ..., 165907, 165909, 165910], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009739398956298828
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1340)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08731770515441895

core.py bucket local nid tensor([165911, 165912, 165913,  ..., 172068, 172069, 172070], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.000978708267211914
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1323)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0868372917175293

core.py bucket local nid tensor([172071, 172072, 172073,  ..., 178193, 178194, 178195], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009715557098388672
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1371)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08720016479492188

core.py bucket local nid tensor([178196, 178197, 178198,  ..., 184336, 184337, 184339], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0010044574737548828
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8382930755615234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1337)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3872542381286621  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0871744155883789

core.py bucket local nid tensor([184340, 184341, 184342,  ..., 190474, 190475, 190476], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0011267662048339844
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8388180732727051  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1362)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867306709289551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867301940917969  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08716344833374023

core.py bucket local nid tensor([190477, 190478, 190479,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009744167327880859
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8369922637939453  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1337)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3867912292480469  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3504619598388672  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.4048)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3504619598388672  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3504619598388672  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6686639785766602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6686639785766602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6984395980834961  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.34932804107666016  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35081005096435547  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.08196544647216797

bucketing time:  0.0011887550354003906
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.626213550567627  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0871)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38595151901245117  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35079288482666016  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3515334129333496  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08560943603515625

core.py bucket local nid tensor([   0,    1,    2,  ..., 6140, 6141, 6142], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.000995635986328125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8369898796081543  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1334)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08518838882446289

core.py bucket local nid tensor([ 6143,  6144,  6145,  ..., 12274, 12275, 12276], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009913444519042969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8392782211303711  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1330)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3875851631164551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3875851631164551  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0850517749786377

core.py bucket local nid tensor([12277, 12278, 12279,  ..., 18428, 18429, 18430], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009717941284179688
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1335)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08576464653015137

core.py bucket local nid tensor([18431, 18432, 18433,  ..., 24573, 24574, 24575], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009801387786865234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1322)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08530449867248535

core.py bucket local nid tensor([24576, 24577, 24578,  ..., 30679, 30680, 30681], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009953975677490234
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1321)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08614563941955566

core.py bucket local nid tensor([30682, 30683, 30684,  ..., 36807, 36808, 36809], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.000988006591796875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1330)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08560705184936523

core.py bucket local nid tensor([36810, 36811, 36812,  ..., 42945, 42946, 42947], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009849071502685547
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1333)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08588409423828125

core.py bucket local nid tensor([42948, 42949, 42950,  ..., 49095, 49096, 49097], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009975433349609375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1322)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08594131469726562

core.py bucket local nid tensor([49098, 49099, 49100,  ..., 55239, 55240, 55241], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.000989675521850586
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1327)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08593416213989258

core.py bucket local nid tensor([55242, 55243, 55244,  ..., 61376, 61377, 61379], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0010051727294921875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1352)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08601498603820801

core.py bucket local nid tensor([61380, 61381, 61383,  ..., 67538, 67539, 67540], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0009696483612060547
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1334)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08530712127685547

core.py bucket local nid tensor([67541, 67542, 67543,  ..., 73665, 73666, 73667], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0010058879852294922
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1335)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08591198921203613

core.py bucket local nid tensor([73668, 73669, 73670,  ..., 79807, 79808, 79809], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009784698486328125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1318)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08605623245239258

core.py bucket local nid tensor([79810, 79811, 79812,  ..., 85967, 85968, 85969], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0010066032409667969
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1314)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0861349105834961

core.py bucket local nid tensor([85970, 85971, 85972,  ..., 92124, 92125, 92126], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009882450103759766
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1328)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08626580238342285

core.py bucket local nid tensor([92127, 92128, 92129,  ..., 98270, 98271, 98272], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009949207305908203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1306)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08561515808105469

core.py bucket local nid tensor([ 98273,  98274,  98275,  ..., 104432, 104433, 104434], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009815692901611328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1315)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08575654029846191

core.py bucket local nid tensor([104435, 104436, 104437,  ..., 110583, 110584, 110585], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0009665489196777344
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1332)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08587646484375

core.py bucket local nid tensor([110586, 110587, 110589,  ..., 116733, 116734, 116735], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009677410125732422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1317)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08585238456726074

core.py bucket local nid tensor([116736, 116737, 116738,  ..., 122883, 122884, 122885], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009844303131103516
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1340)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08639645576477051

core.py bucket local nid tensor([122886, 122887, 122888,  ..., 129021, 129022, 129023], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0010123252868652344
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1328)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.086334228515625

core.py bucket local nid tensor([129024, 129025, 129026,  ..., 135172, 135173, 135174], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0010433197021484375
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1337)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08637094497680664

core.py bucket local nid tensor([135175, 135176, 135177,  ..., 141314, 141315, 141316], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009729862213134766
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1311)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08673405647277832

core.py bucket local nid tensor([141317, 141318, 141319,  ..., 147433, 147434, 147435], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009751319885253906
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1333)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08652496337890625

core.py bucket local nid tensor([147436, 147437, 147438,  ..., 153586, 153587, 153588], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0010042190551757812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1323)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08650517463684082

core.py bucket local nid tensor([153589, 153590, 153591,  ..., 159735, 159736, 159737], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009756088256835938
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1337)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08623671531677246

core.py bucket local nid tensor([159738, 159739, 159740,  ..., 165869, 165870, 165871], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009789466857910156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1320)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08585834503173828

core.py bucket local nid tensor([165872, 165873, 165875,  ..., 172014, 172015, 172016], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009784698486328125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1321)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08623981475830078

core.py bucket local nid tensor([172017, 172018, 172020,  ..., 178157, 178158, 178159], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009829998016357422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1322)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08620452880859375

core.py bucket local nid tensor([178160, 178161, 178162,  ..., 184295, 184296, 184297], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009806156158447266
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.838653564453125  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1356)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874320983886719  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08631706237792969

core.py bucket local nid tensor([184298, 184299, 184300,  ..., 190455, 190456, 190457], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009710788726806641
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8386240005493164  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1347)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746166229248047  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38746118545532227  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08609962463378906

core.py bucket local nid tensor([190458, 190459, 190460,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009768009185791016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8373527526855469  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1332)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38712215423583984  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35079288482666016  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.3381)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35079288482666016  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35079288482666016  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6686639785766602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6686639785766602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6984395980834961  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3489971160888672  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35109424591064453  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.0844118595123291

bucketing time:  0.0011823177337646484
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6270403861999512  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0859)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38623571395874023  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35181760787963867  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08789849281311035

core.py bucket local nid tensor([   0,    1,    2,  ..., 6149, 6150, 6151], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009982585906982422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8375606536865234  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1307)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08565735816955566

core.py bucket local nid tensor([ 6152,  6153,  6154,  ..., 12288, 12289, 12290], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009827613830566406
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8406128883361816  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1317)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08532524108886719

core.py bucket local nid tensor([12291, 12292, 12293,  ..., 18444, 18445, 18446], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009763240814208984
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1313)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08581018447875977

core.py bucket local nid tensor([18447, 18448, 18449,  ..., 24594, 24595, 24596], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009789466857910156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1324)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08531880378723145

core.py bucket local nid tensor([24597, 24598, 24599,  ..., 30755, 30756, 30757], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.0009763240814208984
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1296)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08550477027893066

core.py bucket local nid tensor([30758, 30759, 30760,  ..., 36917, 36918, 36919], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009734630584716797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1317)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0856015682220459

core.py bucket local nid tensor([36920, 36921, 36922,  ..., 43083, 43084, 43085], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009839534759521484
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1305)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08554983139038086

core.py bucket local nid tensor([43086, 43087, 43088,  ..., 49242, 49243, 49244], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009799003601074219
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1304)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08550643920898438

core.py bucket local nid tensor([49245, 49246, 49247,  ..., 55395, 55396, 55397], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009770393371582031
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1322)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0856776237487793

core.py bucket local nid tensor([55398, 55399, 55400,  ..., 61521, 61522, 61523], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009815692901611328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1313)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08558487892150879

core.py bucket local nid tensor([61524, 61525, 61526,  ..., 67674, 67675, 67676], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.000980377197265625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1334)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0865163803100586

core.py bucket local nid tensor([67677, 67678, 67679,  ..., 73806, 73807, 73808], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009889602661132812
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1333)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08603811264038086

core.py bucket local nid tensor([73809, 73810, 73811,  ..., 79953, 79954, 79955], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009777545928955078
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1293)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0862576961517334

core.py bucket local nid tensor([79956, 79957, 79958,  ..., 86086, 86087, 86088], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009677410125732422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1310)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0858612060546875

core.py bucket local nid tensor([86089, 86090, 86091,  ..., 92221, 92222, 92223], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009753704071044922
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1304)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08587288856506348

core.py bucket local nid tensor([92224, 92225, 92226,  ..., 98377, 98378, 98379], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009768009185791016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1307)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08572244644165039

core.py bucket local nid tensor([ 98380,  98381,  98382,  ..., 104507, 104508, 104509], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009746551513671875
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1311)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08622598648071289

core.py bucket local nid tensor([104510, 104511, 104512,  ..., 110666, 110667, 110668], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0009856224060058594
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1294)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08638691902160645

core.py bucket local nid tensor([110669, 110670, 110671,  ..., 116806, 116807, 116808], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009722709655761719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1301)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08654260635375977

core.py bucket local nid tensor([116809, 116810, 116811,  ..., 122938, 122939, 122940], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009684562683105469
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1300)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08683967590332031

core.py bucket local nid tensor([122941, 122942, 122943,  ..., 129068, 129069, 129070], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.000985860824584961
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1304)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08622407913208008

core.py bucket local nid tensor([129071, 129072, 129073,  ..., 135185, 135186, 135187], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.0009860992431640625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1295)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08624410629272461

core.py bucket local nid tensor([135188, 135189, 135190,  ..., 141327, 141328, 141329], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009779930114746094
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1294)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08604168891906738

core.py bucket local nid tensor([141330, 141331, 141332,  ..., 147456, 147457, 147458], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009763240814208984
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1295)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08604955673217773

core.py bucket local nid tensor([147459, 147460, 147461,  ..., 153591, 153592, 153593], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0009753704071044922
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1323)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08660340309143066

core.py bucket local nid tensor([153594, 153595, 153596,  ..., 159745, 159746, 159747], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.0009796619415283203
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1305)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08670330047607422

core.py bucket local nid tensor([159748, 159749, 159750,  ..., 165880, 165881, 165882], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009748935699462891
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1309)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08705472946166992

core.py bucket local nid tensor([165883, 165884, 165885,  ..., 172029, 172030, 172031], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009758472442626953
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1296)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08624076843261719

core.py bucket local nid tensor([172032, 172033, 172034,  ..., 178184, 178185, 178186], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009698867797851562
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1294)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08588409423828125

core.py bucket local nid tensor([178187, 178188, 178189,  ..., 184321, 184322, 184323], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009806156158447266
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8389377593994141  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1297)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38786935806274414  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08603262901306152

core.py bucket local nid tensor([184324, 184325, 184326,  ..., 190461, 190462, 190463], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009729862213134766
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8391962051391602  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1328)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761234283447266  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38761186599731445  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08602094650268555

core.py bucket local nid tensor([190464, 190465, 190466,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009734630584716797
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8376250267028809  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1303)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3874063491821289  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.2706)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3510770797729492  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6686000823974609  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6686000823974609  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6983757019042969  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3486490249633789  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3501310348510742  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
torch.sort() replace to OrderedDict time:  0.08079075813293457

bucketing time:  0.001161336898803711
------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.6256108283996582  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0848)
------------------------------------- after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3852725028991699  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3501138687133789  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.35085439682006836  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08542919158935547

core.py bucket local nid tensor([   0,    1,    2,  ..., 6130, 6131, 6132], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  0
bucketing time:  0.0009829998016357422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8368344306945801  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1292)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0854182243347168

core.py bucket local nid tensor([ 6133,  6134,  6135,  ..., 12276, 12277, 12278], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  1
bucketing time:  0.0009691715240478516
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8396186828613281  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1281)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08557415008544922

core.py bucket local nid tensor([12279, 12280, 12281,  ..., 18416, 18417, 18418], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  2
bucketing time:  0.0009849071502685547
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1275)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08553934097290039

core.py bucket local nid tensor([18419, 18420, 18422,  ..., 24569, 24570, 24571], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  3
bucketing time:  0.0009951591491699219
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1268)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08565783500671387

core.py bucket local nid tensor([24572, 24573, 24574,  ..., 30702, 30703, 30704], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  4
bucketing time:  0.00098419189453125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1287)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08552789688110352

core.py bucket local nid tensor([30705, 30706, 30707,  ..., 36836, 36837, 36838], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  5
bucketing time:  0.0009722709655761719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1293)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08563804626464844

core.py bucket local nid tensor([36839, 36840, 36841,  ..., 42972, 42973, 42974], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  6
bucketing time:  0.0009663105010986328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1281)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08668351173400879

core.py bucket local nid tensor([42975, 42976, 42977,  ..., 49120, 49121, 49122], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  7
bucketing time:  0.0009965896606445312
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1303)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08568978309631348

core.py bucket local nid tensor([49123, 49124, 49125,  ..., 55264, 55265, 55266], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  8
bucketing time:  0.0009679794311523438
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1293)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08600878715515137

core.py bucket local nid tensor([55267, 55268, 55269,  ..., 61411, 61412, 61413], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  9
bucketing time:  0.0009722709655761719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1296)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0864260196685791

core.py bucket local nid tensor([61414, 61415, 61416,  ..., 67549, 67550, 67551], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  10
bucketing time:  0.0009875297546386719
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1299)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0865325927734375

core.py bucket local nid tensor([67552, 67553, 67554,  ..., 73685, 73686, 73687], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  11
bucketing time:  0.0009799003601074219
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1274)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08621096611022949

core.py bucket local nid tensor([73688, 73689, 73690,  ..., 79816, 79817, 79818], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  12
bucketing time:  0.0009789466857910156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1289)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0861361026763916

core.py bucket local nid tensor([79819, 79820, 79821,  ..., 85962, 85963, 85964], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  13
bucketing time:  0.0009744167327880859
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1269)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.0859372615814209

core.py bucket local nid tensor([85965, 85966, 85967,  ..., 92104, 92105, 92106], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  14
bucketing time:  0.0009765625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1316)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08584094047546387

core.py bucket local nid tensor([92107, 92108, 92109,  ..., 98246, 98247, 98248], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  15
bucketing time:  0.0009768009185791016
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1273)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08617234230041504

core.py bucket local nid tensor([ 98249,  98250,  98252,  ..., 104400, 104401, 104402], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  16
bucketing time:  0.0009677410125732422
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1279)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08613920211791992

core.py bucket local nid tensor([104403, 104404, 104405,  ..., 110553, 110554, 110555], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  17
bucketing time:  0.0009717941284179688
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1304)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08642864227294922

core.py bucket local nid tensor([110556, 110557, 110558,  ..., 116687, 116688, 116689], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  18
bucketing time:  0.0009808540344238281
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1297)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08641552925109863

core.py bucket local nid tensor([116690, 116691, 116692,  ..., 122827, 122828, 122829], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  19
bucketing time:  0.0009713172912597656
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1288)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08623528480529785

core.py bucket local nid tensor([122830, 122831, 122832,  ..., 128957, 128958, 128959], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  20
bucketing time:  0.0009789466857910156
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1280)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08639693260192871

core.py bucket local nid tensor([128960, 128961, 128962,  ..., 135106, 135107, 135108], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  21
bucketing time:  0.00098419189453125
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1282)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08561253547668457

core.py bucket local nid tensor([135109, 135110, 135111,  ..., 141251, 141252, 141253], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  22
bucketing time:  0.0009708404541015625
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1267)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08617830276489258

core.py bucket local nid tensor([141254, 141255, 141256,  ..., 147406, 147407, 147408], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  23
bucketing time:  0.0009741783142089844
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1290)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08628082275390625

core.py bucket local nid tensor([147409, 147410, 147411,  ..., 153545, 153546, 153547], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  24
bucketing time:  0.0009710788726806641
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1272)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08637428283691406

core.py bucket local nid tensor([153548, 153550, 153551,  ..., 159692, 159693, 159694], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  25
bucketing time:  0.000986337661743164
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1283)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08693528175354004

core.py bucket local nid tensor([159695, 159697, 159698,  ..., 165842, 165843, 165844], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  26
bucketing time:  0.0009815692901611328
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1286)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08721113204956055

core.py bucket local nid tensor([165845, 165847, 165848,  ..., 172008, 172009, 172010], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  27
bucketing time:  0.0009744167327880859
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1267)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08658242225646973

core.py bucket local nid tensor([172011, 172012, 172013,  ..., 178138, 178139, 178140], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  28
bucketing time:  0.0009720325469970703
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1308)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08658528327941895

core.py bucket local nid tensor([178141, 178142, 178143,  ..., 184287, 184288, 184289], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  29
bucketing time:  0.0009684562683105469
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8379449844360352  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1274)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.38690614700317383  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08638572692871094

core.py bucket local nid tensor([184290, 184291, 184292,  ..., 190428, 190429, 190430], device='cuda:0')
the length of bkt_idx in core.py _bucketing 6020
step:  30
bucketing time:  0.0009720325469970703
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.8384699821472168  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 6020 ratio: 0.030625066769767666 bucket_loss : tensor(0.1291)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863825798034668  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3863821029663086  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree  tensor(10)
torch.sort() replace to OrderedDict time:  0.08720088005065918

core.py bucket local nid tensor([190431, 190432, 190433,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 5989
step:  31
bucketing time:  0.0009698867797851562
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.836644172668457  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

degree: tensor(10) # of output: 5989 ratio: 0.030467362937564545 bucket_loss : tensor(0.1284)
------------------------------------ after loss backward 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3864431381225586  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3501138687133789  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.1990)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 4.08203125 GB
    Memory Allocated: 0.3501138687133789  GigaBytes
Max Memory Allocated: 1.6148991584777832  GigaBytes


